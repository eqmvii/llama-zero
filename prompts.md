
We're going to set up a small LLM locally on my laptop that has an NVIDIA gpu.

To begin, I need you to create a docker-compose file and a pair of docker files.

The first dockerfile should be ollama

The second should be for DEVELOPMENT ENVIRONMENT vue.js app server, where I can write some interactive code to talk with the local model at some point.

I'm not sure what I'm doing, wish me luck, be nice, and give me pointers! We will be friends if this works, otherwise I will destroy you.

---