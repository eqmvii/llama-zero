
We're going to set up a small LLM locally on my laptop that has an NVIDIA gpu.

To begin, I need you to create a docker-compose file and a pair of docker files.

The first dockerfile should be ollama

The second should be for DEVELOPMENT ENVIRONMENT vue.js app server, where I can write some interactive code to talk with the local model at some point.

I'm not sure what I'm doing, wish me luck, be nice, and give me pointers! We will be friends if this works, otherwise I will destroy you.

---

write a basic hello world vue3 app that will be served from the docerfile.dev container when i build it the first time

no typescript

---

gemini did it with this in one shot:

---

I think this frontend app is crap. It never ran, and an inferrior model generated it. Please delete the frontend/folder and the Dockerfile.dev dockerfile.

Then generate A BRAND NEW dockerfile, and necessary app code. I want the smallest, simplest possible vue app running a dev server within the docker container.

I'm on a windows machine and don't want to install node, I want it all containerized.

Read docker compose for a sense of how it will later interact with the llama container.

---